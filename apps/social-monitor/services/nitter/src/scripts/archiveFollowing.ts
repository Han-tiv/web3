import path from 'path';
import fs from 'fs/promises';
import { setTimeout as delay } from 'timers/promises';
import {
  NitterUserService,
  TimelineTweet
} from '../userService';
import {
  buildMarkdown,
  deduplicateTweets,
  sanitizeHandle
} from '../archive/format';
import {
  AccountArchive,
  ArchivedTweet,
  ArchiveMeta,
  FollowingAccount
} from '../archive/types';

interface CliOptions {
  inputPath: string;
  outputDir: string;
  tweetLimit: number;
  delayMs: number;
  pageDelayMs: number;
  retries: number;
  maxPages?: number;
  limitAccounts?: number;
  handlesFilter?: Set<string>;
  skipMarkdown: boolean;
  skipExisting: boolean;
  dryRun: boolean;
  stateFile: string;
}

interface FetchResult {
  tweets: ArchivedTweet[];
  pagesFetched: number;
  cursorTrail: string[];
  errors: string[];
  durationMs: number;
  attempts: number;
}

interface ArchiveRunResult {
  handle: string;
  tweetsFetched: number;
  pagesFetched: number;
  durationMs: number;
  attempts: number;
  errors?: string[];
  outputDir: string;
  skipped: boolean;
}

interface ArchiveRunSummary {
  startedAt: string;
  finishedAt?: string;
  options: {
    tweetLimit: number;
    delayMs: number;
    pageDelayMs: number;
    retries: number;
    maxPages?: number;
    handlesPlanned: number;
  };
  results: ArchiveRunResult[];
}

/**
 * åŸºäºå‘½ä»¤è¡Œå‚æ•°é…ç½®æŠ“å–è¡Œä¸ºã€‚
 */
function parseArgs(argv: string[]): CliOptions {
  const defaults = {
    inputPath: path.resolve(process.cwd(), '../../../..', 'twitter-Following-1760964620895.json'),
    outputDir: path.resolve(process.cwd(), 'data', 'following'),
    tweetLimit: 200,
    delayMs: 3000,
    pageDelayMs: 1500,
    retries: 2,
    maxPages: 50,
    limitAccounts: undefined,
    handlesFilter: undefined,
    skipMarkdown: false,
    skipExisting: false,
    dryRun: false,
    stateFile: undefined as string | undefined
  };

  const options: Partial<CliOptions> = {};

  for (let i = 0; i < argv.length; i++) {
    const arg = argv[i];
    if (!arg.startsWith('--')) continue;

    const [flag, inlineValue] = arg.includes('=') ? arg.split('=', 2) : [arg, undefined];
    const value = inlineValue ?? argv[i + 1];

    switch (flag) {
      case '--input':
        if (!value) throw new Error('ç¼ºå°‘ --input å‚æ•°å€¼');
        options.inputPath = path.resolve(process.cwd(), value);
        if (!inlineValue) i++;
        break;
      case '--output':
        if (!value) throw new Error('ç¼ºå°‘ --output å‚æ•°å€¼');
        options.outputDir = path.resolve(process.cwd(), value);
        if (!inlineValue) i++;
        break;
      case '--tweet-limit':
        if (!value) throw new Error('ç¼ºå°‘ --tweet-limit å‚æ•°å€¼');
        options.tweetLimit = toPositiveInt(value, 'tweet-limit');
        if (!inlineValue) i++;
        break;
      case '--delay':
        if (!value) throw new Error('ç¼ºå°‘ --delay å‚æ•°å€¼');
        options.delayMs = toNonNegativeInt(value, 'delay');
        if (!inlineValue) i++;
        break;
      case '--page-delay':
        if (!value) throw new Error('ç¼ºå°‘ --page-delay å‚æ•°å€¼');
        options.pageDelayMs = toNonNegativeInt(value, 'page-delay');
        if (!inlineValue) i++;
        break;
      case '--retries':
        if (!value) throw new Error('ç¼ºå°‘ --retries å‚æ•°å€¼');
        options.retries = toNonNegativeInt(value, 'retries');
        if (!inlineValue) i++;
        break;
      case '--max-pages':
        if (!value) throw new Error('ç¼ºå°‘ --max-pages å‚æ•°å€¼');
        options.maxPages = toNonNegativeInt(value, 'max-pages');
        if (!inlineValue) i++;
        break;
      case '--limit-accounts':
        if (!value) throw new Error('ç¼ºå°‘ --limit-accounts å‚æ•°å€¼');
        options.limitAccounts = toPositiveInt(value, 'limit-accounts');
        if (!inlineValue) i++;
        break;
      case '--handles':
        if (!value) throw new Error('ç¼ºå°‘ --handles å‚æ•°å€¼');
        options.handlesFilter = new Set(
          value.split(',').map(item => item.trim().toLowerCase()).filter(Boolean)
        );
        if (!inlineValue) i++;
        break;
      case '--skip-markdown':
        options.skipMarkdown = true;
        break;
      case '--skip-existing':
        options.skipExisting = true;
        break;
      case '--dry-run':
        options.dryRun = true;
        break;
      case '--state-file':
        if (!value) throw new Error('ç¼ºå°‘ --state-file å‚æ•°å€¼');
        options.stateFile = path.resolve(process.cwd(), value);
        if (!inlineValue) i++;
        break;
      default:
        throw new Error(`æœªçŸ¥å‚æ•°ï¼š${flag}`);
    }
  }

  const merged: CliOptions = {
    ...defaults,
    ...options,
    // stateFile é»˜è®¤æ”¾åœ¨è¾“å‡ºç›®å½•
    stateFile: options.stateFile
      ? options.stateFile
      : path.join(options.outputDir ?? defaults.outputDir, 'archive-state.json')
  } as CliOptions;

  return merged;
}

function toPositiveInt(value: string, field: string): number {
  const parsed = Number.parseInt(value, 10);
  if (!Number.isFinite(parsed) || parsed <= 0) {
    throw new Error(`${field} å¿…é¡»æ˜¯æ­£æ•´æ•°`);
  }
  return parsed;
}

function toNonNegativeInt(value: string, field: string): number {
  const parsed = Number.parseInt(value, 10);
  if (!Number.isFinite(parsed) || parsed < 0) {
    throw new Error(`${field} å¿…é¡»æ˜¯éè´Ÿæ•´æ•°`);
  }
  return parsed;
}

async function ensureDir(dir: string): Promise<void> {
  await fs.mkdir(dir, { recursive: true });
}

async function pathExists(filePath: string): Promise<boolean> {
  try {
    await fs.access(filePath);
    return true;
  } catch {
    return false;
  }
}

async function loadFollowing(inputPath: string): Promise<FollowingAccount[]> {
  const raw = await fs.readFile(inputPath, 'utf8');
  const parsed = JSON.parse(raw);
  if (!Array.isArray(parsed)) {
    throw new Error('å…³æ³¨åˆ—è¡¨æ–‡ä»¶æ ¼å¼å¿…é¡»ä¸ºæ•°ç»„');
  }
  return parsed as FollowingAccount[];
}

function filterAccounts(
  accounts: FollowingAccount[],
  { handlesFilter, limitAccounts }: Pick<CliOptions, 'handlesFilter' | 'limitAccounts'>
): FollowingAccount[] {
  let result = accounts;

  if (handlesFilter && handlesFilter.size > 0) {
    result = result.filter(account => handlesFilter.has(account.screen_name.toLowerCase()));
  }

  if (typeof limitAccounts === 'number') {
    result = result.slice(0, limitAccounts);
  }

  return result;
}

function normalizeTweet(raw: TimelineTweet, handle: string): ArchivedTweet {
  const id = raw.id ? String(raw.id) : '';
  const timestamp = safeTimestamp(raw.timestamp);
  const content = typeof raw.content === 'string' ? raw.content.trim() : '';
  const url =
    typeof raw.url === 'string' && raw.url.length > 0
      ? raw.url
      : `https://twitter.com/${handle}/status/${id}`;

  return {
    id,
    content,
    timestamp,
    url,
    author: raw.author || handle
  };
}

function safeTimestamp(value?: string): string {
  if (!value) {
    return new Date().toISOString();
  }
  const parsed = new Date(value);
  if (Number.isNaN(parsed.getTime())) {
    return value;
  }
  return parsed.toISOString();
}

async function collectTweetsWithRetry(
  userService: NitterUserService,
  handle: string,
  limit: number,
  maxPages: number | undefined,
  pageDelayMs: number,
  retries: number
): Promise<FetchResult> {
  const errors: string[] = [];
  const started = Date.now();
  let attempts = 0;
  let lastResult: { tweets: ArchivedTweet[]; pagesFetched: number; cursorTrail: string[] } = {
    tweets: [],
    pagesFetched: 0,
    cursorTrail: []
  };

  while (attempts <= retries) {
    attempts += 1;
    try {
      lastResult = await collectTweets(
        userService,
        handle,
        limit,
        maxPages,
        pageDelayMs
      );

      if (lastResult.tweets.length > 0 || attempts > retries) {
        break;
      }
      errors.push(`ç¬¬ ${attempts} æ¬¡æŠ“å–ç»“æœä¸ºç©ºï¼Œå‡†å¤‡é‡è¯•`);
    } catch (error) {
      const message = error instanceof Error ? error.message : String(error);
      errors.push(`ç¬¬ ${attempts} æ¬¡æŠ“å–å¼‚å¸¸ï¼š${message}`);
    }

    if (attempts <= retries) {
      await delay(1000 * attempts);
    }
  }

  return {
    tweets: deduplicateTweets(lastResult.tweets),
    pagesFetched: lastResult.pagesFetched,
    cursorTrail: lastResult.cursorTrail,
    errors,
    durationMs: Date.now() - started,
    attempts
  };
}

async function collectTweets(
  userService: NitterUserService,
  handle: string,
  limit: number,
  maxPages: number | undefined,
  pageDelayMs: number
): Promise<{ tweets: ArchivedTweet[]; pagesFetched: number; cursorTrail: string[] }> {
  const effectiveLimit = limit > 0 ? limit : Number.POSITIVE_INFINITY;
  const effectiveMaxPages = typeof maxPages === 'number' && maxPages > 0
    ? maxPages
    : Number.POSITIVE_INFINITY;

  const tweets: ArchivedTweet[] = [];
  const cursorTrail: string[] = [];
  const seen = new Set<string>();
  let cursor: string | undefined;
  let pagesFetched = 0;

  while (pagesFetched < effectiveMaxPages) {
    const page = await userService.getUserTimelinePage(handle, { cursor });
    pagesFetched += 1;

    page.tweets.forEach(rawTweet => {
      if (tweets.length >= effectiveLimit) {
        return;
      }
      if (!rawTweet.id) {
        return;
      }
      if (seen.has(rawTweet.id)) {
        return;
      }
      seen.add(rawTweet.id);
      tweets.push(normalizeTweet(rawTweet, handle));
    });

    if (!page.nextCursor) {
      break;
    }

    if (tweets.length >= effectiveLimit) {
      break;
    }

    if (cursorTrail.includes(page.nextCursor)) {
      break;
    }

    cursorTrail.push(page.nextCursor);
    cursor = page.nextCursor;

    if (pageDelayMs > 0) {
      const jitter = Math.floor(Math.random() * Math.max(500, Math.round(pageDelayMs * 0.2)));
      await delay(pageDelayMs + jitter);
    }
  }

  return {
    tweets: effectiveLimit === Number.POSITIVE_INFINITY ? tweets : tweets.slice(0, effectiveLimit),
    pagesFetched,
    cursorTrail
  };
}

function toArchive(account: FollowingAccount, meta: ArchiveMeta, tweets: ArchivedTweet[]): AccountArchive {
  const { metadata, ...rest } = account as FollowingAccount & { metadata?: any };

  const snapshot: FollowingAccount = {
    ...rest,
    description: account.description ?? '',
    website: account.website ?? ''
  };

  if (metadata?.rest_id) {
    snapshot.rest_id = metadata.rest_id;
  }
  if (metadata?.core?.created_at && !snapshot.created_at) {
    snapshot.created_at = metadata.core.created_at;
  }

  return {
    account: snapshot,
    tweets,
    meta
  };
}

async function writeArchiveFiles(
  archive: AccountArchive,
  accountDir: string,
  skipMarkdown: boolean,
  dryRun: boolean
): Promise<void> {
  if (dryRun) {
    console.log(`[dry-run] å°†åœ¨ ${accountDir} å†™å…¥ ${archive.tweets.length} æ¡æ¨æ–‡`);
    return;
  }

  await ensureDir(accountDir);

  const jsonPath = path.join(accountDir, 'tweets.json');
  await fs.writeFile(jsonPath, JSON.stringify(archive, null, 2), 'utf8');

  if (!skipMarkdown) {
    const markdownPath = path.join(accountDir, 'tweets.md');
    const markdown = buildMarkdown(archive);
    await fs.writeFile(markdownPath, markdown, 'utf8');
  }
}

async function persistSummary(
  summary: ArchiveRunSummary,
  stateFile: string,
  dryRun: boolean
): Promise<void> {
  if (dryRun) {
    return;
  }
  await ensureDir(path.dirname(stateFile));
  summary.finishedAt = new Date().toISOString();
  await fs.writeFile(stateFile, JSON.stringify(summary, null, 2), 'utf8');
}

async function main(): Promise<void> {
  const options = parseArgs(process.argv.slice(2));
  console.log('ğŸ“¥ å½’æ¡£é…ç½®ï¼š', {
    input: options.inputPath,
    output: options.outputDir,
    tweetLimit: options.tweetLimit,
    delayMs: options.delayMs,
    pageDelayMs: options.pageDelayMs,
    retries: options.retries,
    maxPages: options.maxPages,
    limitAccounts: options.limitAccounts,
    handlesFilter: options.handlesFilter ? Array.from(options.handlesFilter) : undefined,
    skipMarkdown: options.skipMarkdown,
    skipExisting: options.skipExisting,
    dryRun: options.dryRun,
    stateFile: options.stateFile
  });

  const accounts = await loadFollowing(options.inputPath);
  const filtered = filterAccounts(accounts, options);
  console.log(`ğŸ“š è¾“å…¥è´¦å·æ€»æ•°ï¼š${accounts.length}ï¼Œæœ¬æ¬¡å¤„ç†ï¼š${filtered.length}`);

  if (!options.dryRun) {
    await ensureDir(options.outputDir);
  }

  const summary: ArchiveRunSummary = {
    startedAt: new Date().toISOString(),
    options: {
      tweetLimit: options.tweetLimit,
      delayMs: options.delayMs,
      pageDelayMs: options.pageDelayMs,
      retries: options.retries,
      maxPages: options.maxPages,
      handlesPlanned: filtered.length
    },
    results: []
  };

  const userService = new NitterUserService();

  for (let index = 0; index < filtered.length; index++) {
    const account = filtered[index];
    const handle = account.screen_name;
    const safeHandle = sanitizeHandle(handle);
    const accountDir = path.join(options.outputDir, safeHandle);
    const jsonPath = path.join(accountDir, 'tweets.json');

    console.log(`\n[${index + 1}/${filtered.length}] â³ å¤„ç† @${handle} ...`);

    if (options.skipExisting && !options.dryRun && await pathExists(jsonPath)) {
      console.log(`âš ï¸ æ£€æµ‹åˆ°å·²å­˜åœ¨çš„å½’æ¡£æ–‡ä»¶ ${jsonPath}ï¼Œæ ¹æ®å‚æ•°è·³è¿‡æŠ“å–ã€‚`);
      summary.results.push({
        handle,
        tweetsFetched: 0,
        pagesFetched: 0,
        durationMs: 0,
        attempts: 0,
        errors: undefined,
        outputDir: accountDir,
        skipped: true
      });
      await persistSummary(summary, options.stateFile, options.dryRun);
      continue;
    }

    const fetchResult = await collectTweetsWithRetry(
      userService,
      handle,
      options.tweetLimit,
      options.maxPages,
      options.pageDelayMs,
      options.retries
    );

    const archiveMeta: ArchiveMeta = {
      capturedAt: new Date().toISOString(),
      tweetLimit: options.tweetLimit,
      tweetsFetched: fetchResult.tweets.length,
      pagesFetched: fetchResult.pagesFetched,
      sourceFile: path.basename(options.inputPath),
      errors: fetchResult.errors.length ? fetchResult.errors : undefined,
      durationMs: fetchResult.durationMs,
      cursorTrail: fetchResult.cursorTrail.length ? fetchResult.cursorTrail : undefined,
      attempts: fetchResult.attempts,
      skipped: false
    };

    const archive = toArchive(account, archiveMeta, fetchResult.tweets);

    await writeArchiveFiles(
      archive,
      accountDir,
      options.skipMarkdown,
      options.dryRun
    );

    console.log(
      `âœ… å®Œæˆ @${handle}ï¼Œå†™å…¥ ${fetchResult.tweets.length} æ¡æ¨æ–‡ï¼ˆåˆ†é¡µ ${fetchResult.pagesFetched} æ¬¡ï¼Œå°è¯• ${fetchResult.attempts} æ¬¡ï¼Œè€—æ—¶ ${Math.round(fetchResult.durationMs)} msï¼‰`
    );
    if (fetchResult.errors.length) {
      fetchResult.errors.forEach(msg => console.warn(`âš ï¸ ${msg}`));
    }

    summary.results.push({
      handle,
      tweetsFetched: fetchResult.tweets.length,
      pagesFetched: fetchResult.pagesFetched,
      durationMs: fetchResult.durationMs,
      attempts: fetchResult.attempts,
      errors: fetchResult.errors.length ? fetchResult.errors : undefined,
      outputDir: accountDir,
      skipped: false
    });
    await persistSummary(summary, options.stateFile, options.dryRun);

    if (index < filtered.length - 1 && options.delayMs > 0) {
      const jitter = Math.floor(Math.random() * Math.max(1000, Math.round(options.delayMs * 0.3)));
      await delay(options.delayMs + jitter);
    }
  }

  console.log('\nğŸ‰ å¤„ç†å®Œæˆ');
}

if (require.main === module) {
  main().catch(error => {
    console.error('å½’æ¡£è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼š', error);
    process.exitCode = 1;
  });
}

export {
  buildMarkdown,
  deduplicateTweets,
  sanitizeHandle,
  parseArgs,
  loadFollowing,
  filterAccounts,
  collectTweetsWithRetry as fetchTweetsWithRetry,
  normalizeTweet,
  toArchive
};
