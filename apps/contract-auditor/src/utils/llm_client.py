"""
LLM å®¢æˆ·ç«¯æ¨¡å—
æ”¯æŒ Ollama API å’Œ OpenAI å…¼å®¹æŽ¥å£
"""
import json
import requests
from typing import Dict, Any, Optional, List
from dataclasses import dataclass
import logging

logger = logging.getLogger(__name__)


@dataclass
class LLMResponse:
    """LLM å“åº”æ•°æ®ç±»"""
    content: str
    tokens_used: int
    confidence: float = 0.0
    metadata: Dict[str, Any] = None


class LLMClient:
    """LLM å®¢æˆ·ç«¯"""

    def __init__(self, api_url: str, model: str, api_key: Optional[str] = None):
        self.api_url = api_url
        self.model = model
        self.api_key = api_key
        self.total_tokens = 0

    def generate(self, prompt: str, **kwargs) -> LLMResponse:
        """
        ç”Ÿæˆå“åº”

        Args:
            prompt: è¾“å…¥æç¤ºè¯
            **kwargs: é¢å¤–å‚æ•°ï¼ˆtemperature, max_tokensç­‰ï¼‰

        Returns:
            LLMResponse: å“åº”å¯¹è±¡
        """
        try:
            # æž„å»ºè¯·æ±‚ä½“
            payload = {
                "model": self.model,
                "prompt": prompt,
                "stream": False,
                **kwargs
            }

            # æ·»åŠ  API Keyï¼ˆå¦‚æžœæœ‰ï¼‰
            headers = {}
            if self.api_key:
                headers["Authorization"] = f"Bearer {self.api_key}"

            # å‘é€è¯·æ±‚
            response = requests.post(
                self.api_url,
                json=payload,
                headers=headers,
                timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
            )
            response.raise_for_status()

            # è§£æžå“åº”
            data = response.json()

            # Ollama API æ ¼å¼
            if "response" in data:
                content = data["response"]
                tokens_used = data.get("eval_count", 0) + data.get("prompt_eval_count", 0)
            # OpenAI å…¼å®¹æ ¼å¼
            elif "choices" in data:
                content = data["choices"][0]["message"]["content"]
                tokens_used = data.get("usage", {}).get("total_tokens", 0)
            else:
                raise ValueError(f"æœªçŸ¥çš„å“åº”æ ¼å¼: {data}")

            self.total_tokens += tokens_used

            logger.info(f"âœ… LLM å“åº”æˆåŠŸ ({tokens_used} tokens)")

            return LLMResponse(
                content=content,
                tokens_used=tokens_used,
                metadata=data
            )

        except requests.exceptions.Timeout:
            logger.error("âŒ LLM è¯·æ±‚è¶…æ—¶")
            raise
        except requests.exceptions.RequestException as e:
            logger.error(f"âŒ LLM è¯·æ±‚å¤±è´¥: {e}")
            raise
        except Exception as e:
            logger.error(f"âŒ LLM å¤„ç†é”™è¯¯: {e}")
            raise

    def extract_json(self, response: LLMResponse) -> Dict[str, Any]:
        """
        ä»Žå“åº”ä¸­æå– JSON

        Args:
            response: LLM å“åº”

        Returns:
            Dict: è§£æžçš„ JSON å¯¹è±¡
        """
        content = response.content.strip()

        # å°è¯•ç›´æŽ¥è§£æž
        try:
            return json.loads(content)
        except json.JSONDecodeError:
            pass

        # æŸ¥æ‰¾ JSON ä»£ç å—
        if "```json" in content:
            start = content.find("```json") + 7
            end = content.find("```", start)
            json_str = content[start:end].strip()
        elif "```" in content:
            start = content.find("```") + 3
            end = content.find("```", start)
            json_str = content[start:end].strip()
        else:
            # å°è¯•æå– {} æˆ– []
            for char in ['{', '[']:
                if char in content:
                    start = content.find(char)
                    for end_char in ['}', ']']:
                        end = content.rfind(end_char)
                        if end > start:
                            json_str = content[start:end+1]
                            break
                    break
            else:
                raise ValueError("æ— æ³•ä»Žå“åº”ä¸­æå– JSON")

        try:
            return json.loads(json_str)
        except json.JSONDecodeError as e:
            logger.error(f"âŒ JSON è§£æžå¤±è´¥: {e}")
            logger.error(f"å†…å®¹: {json_str[:200]}")
            raise


class DualModelSystem:
    """åŒæ¨¡åž‹åä½œç³»ç»Ÿ"""

    def __init__(self, reasoning_model: str, coding_model: str, api_url: str):
        self.reasoning_client = LLMClient(api_url, reasoning_model)
        self.coding_client = LLMClient(api_url, coding_model)

        logger.info(f"ðŸ§  æŽ¨ç†æ¨¡åž‹: {reasoning_model}")
        logger.info(f"ðŸ’» ç¼–ç æ¨¡åž‹: {coding_model}")

    def analyze(self, prompt: str, **kwargs) -> LLMResponse:
        """ä½¿ç”¨æŽ¨ç†æ¨¡åž‹åˆ†æž"""
        logger.info("ðŸ” è°ƒç”¨æŽ¨ç†æ¨¡åž‹...")
        return self.reasoning_client.generate(prompt, **kwargs)

    def generate_code(self, prompt: str, **kwargs) -> LLMResponse:
        """ä½¿ç”¨ç¼–ç æ¨¡åž‹ç”Ÿæˆä»£ç """
        logger.info("ðŸ’» è°ƒç”¨ç¼–ç æ¨¡åž‹...")
        return self.coding_client.generate(prompt, **kwargs)

    @property
    def total_tokens(self) -> int:
        """æ€»æ¶ˆè€— tokens"""
        return self.reasoning_client.total_tokens + self.coding_client.total_tokens
