from __future__ import annotations

from typing import Any, Dict, Iterable, List

import pandas as pd
import streamlit as st

from .styling import render_severity_badge

SEVERITY_ORDER = {
    "CRITICAL": 0,
    "HIGH": 1,
    "MEDIUM": 2,
    "LOW": 3,
    "INFO": 4,
    "UNKNOWN": 5,
}


def _normalize_severity(raw: Any) -> str:
    """统一严重级别表示，便于排序与展示。"""
    if raw is None:
        return "UNKNOWN"
    text = str(raw).strip()
    if not text:
        return "UNKNOWN"

    upper = text.upper()
    mapping = {
        "CRITICAL": "CRITICAL",
        "HIGH": "HIGH",
        "H": "HIGH",
        "MEDIUM": "MEDIUM",
        "M": "MEDIUM",
        "LOW": "LOW",
        "L": "LOW",
        "INFO": "INFO",
    }
    if upper in mapping:
        return mapping[upper]
    return "UNKNOWN"


def render_vulnerability_list(vulnerabilities: Iterable[Dict[str, Any]]) -> None:
    """渲染漏洞列表，包括过滤控件与表格/详情视图。"""
    vulns: List[Dict[str, Any]] = list(vulnerabilities or [])
    if not vulns:
        st.info("本次审计未发现任何漏洞。")
        return

    # 预处理字段
    for v in vulns:
        v["_severity_norm"] = _normalize_severity(v.get("severity"))
        try:
            v["_confidence"] = float(v.get("confidence", 0.0) or 0.0)
        except (TypeError, ValueError):
            v["_confidence"] = 0.0
        v["_category"] = v.get("category") or v.get("type") or "未分类"
        v["_target"] = v.get("target") or v.get("location") or ""

    severities = sorted(
        {v["_severity_norm"] for v in vulns},
        key=lambda s: SEVERITY_ORDER.get(s, 99),
    )
    selected_severity = st.multiselect(
        "按严重级别过滤",
        options=severities,
        default=severities,
    )
    keyword = st.text_input(
        "关键字过滤",
        placeholder="按描述、分类或目标函数搜索",
    ).strip()

    def _match(v: Dict[str, Any]) -> bool:
        if selected_severity and v["_severity_norm"] not in selected_severity:
            return False
        if not keyword:
            return True
        text = " ".join(
            [
                str(v.get("description", "")),
                str(v.get("_category", "")),
                str(v.get("_target", "")),
            ]
        ).lower()
        return keyword.lower() in text

    filtered = [v for v in vulns if _match(v)]
    if not filtered:
        st.warning("筛选条件下没有匹配的漏洞。")
        return

    # 表格视图
    table_rows = []
    for idx, v in enumerate(
        sorted(
            filtered,
            key=lambda it: (
                SEVERITY_ORDER.get(it["_severity_norm"], 99),
                -it["_confidence"],
            ),
        ),
        start=1,
    ):
        table_rows.append(
            {
                "序号": idx,
                "分类": v["_category"],
                "严重级别": v["_severity_norm"],
                "置信度": round(v["_confidence"], 3),
                "可利用性": v.get("exploitability", ""),
                "轮次": v.get("round_detected", ""),
            }
        )

    df = pd.DataFrame(table_rows)
    st.dataframe(
        df,
        use_container_width=True,
        hide_index=True,
    )

    # 详情视图
    st.markdown("#### 详情")
    for idx, v in enumerate(filtered, start=1):
        severity_html = render_severity_badge(v.get("_severity_norm", "UNKNOWN"))
        header = (
            f"#{idx} {v['_category']} · "
            f"{v.get('exploitability', '')} · "
            f"轮次 {v.get('round_detected', '-')}"
        )
        with st.expander(header, expanded=(idx == 1)):
            st.markdown(severity_html, unsafe_allow_html=True)
            st.markdown(f"**描述**：{v.get('description', '无')}")
            if v.get("_target"):
                st.markdown(f"**目标位置**：`{v['_target']}`")
            if v.get("recommendation"):
                st.markdown(f"**修复建议**：{v['recommendation']}")
            if v.get("evidence"):
                st.markdown("**证据片段：**")
                st.code(v["evidence"], language="sol")

